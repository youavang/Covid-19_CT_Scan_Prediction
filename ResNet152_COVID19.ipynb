{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResNet152-COVID19.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/youavang/Covid-19_CT_Scan_With_Deep_Learning/blob/main/ResNet152_COVID19.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWpoT_Vm7v2Z"
      },
      "source": [
        "# Down grade to tensorflow to 2.2.0 version in order to use tf-explain Grad CAM\r\n",
        "!pip install tensorflow==2.2.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkTinfeQcJPe"
      },
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('To enable a high-RAM runtime, select the Runtime > \"Change runtime type\"')\n",
        "  print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')\n",
        "  print('re-execute this cell.')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqLTnF7JCO8R"
      },
      "source": [
        "!nvidia-smi #show the allocated GPU"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zw0BhQ7nPihU"
      },
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "import pandas as pd\n",
        "import csv\n",
        "import zipfile\n",
        "from keras import optimizers\n",
        "from keras.models import Sequential, Model, load_model\n",
        "from keras.layers import Dropout, Flatten, Dense, Input, AveragePooling2D, Reshape, Lambda\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization,TimeDistributed, LSTM, concatenate\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "from keras.preprocessing.image import ImageDataGenerator,save_img, load_img, img_to_array\n",
        "from keras.initializers import RandomNormal\n",
        "from sklearn.utils import shuffle\n",
        "import io\n",
        "from PIL import Image as pil_image\n",
        "import keras.backend as k\n",
        "from IPython.display import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "import tensorflow as tf\n",
        "import datetime\n",
        "from keras.callbacks import TensorBoard\n",
        "from keras.applications import ResNet152, InceptionV3, Xception, VGG16, VGG19\n",
        "from keras.applications.resnet_v2 import ResNet50V2\n",
        "from keras.utils.vis_utils import plot_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ry8HQosovrXY"
      },
      "source": [
        "#Connect to your Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1igZiqjnASJF"
      },
      "source": [
        "# Add the COVID-CTset to your drive through this link:\r\n",
        "# https://drive.google.com/drive/folders/1xdk-mCkxCDNwsMAk2SGv203rY1mrbnPB?usp=sharing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UAp6XlqPeou"
      },
      "source": [
        "#Install essential libraries\n",
        "!pip install zipfile36"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bo_5pyzyiZMZ"
      },
      "source": [
        "archive = zipfile.ZipFile(\"/content/drive/MyDrive/Train&Validation.zip\") #Path to the shared data for training and validation\n",
        "for file in archive.namelist():\n",
        "     archive.extract(file, './data') #Extract the data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzN_Dxg5V14k"
      },
      "source": [
        "fold_num=1 #Select Fold Number\r\n",
        "shape=(512,512,1) #shape of the dataset images (in TIFF format)\r\n",
        "num_class=2 #Number of classes (normal and COVID-19)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxGeJBNGjVuN"
      },
      "source": [
        "#Here we set the data generators for applying data augmentation methods\n",
        "train_datagen = ImageDataGenerator(horizontal_flip=True,vertical_flip=True,zoom_range=0.05,rotation_range=360,width_shift_range=0.05,height_shift_range=0.05,shear_range=0.05)\n",
        "test_datagen = ImageDataGenerator()\n",
        "train_df =pd.read_csv('/content/drive/MyDrive/CSV/train{}.csv'.format(fold_num)) #read train csv file\n",
        "validation_df = pd.read_csv('/content/drive/MyDrive/CSV/validation{}.csv'.format(fold_num)) #read validation csv file (Validation in the training process)\n",
        "train_df = shuffle(train_df) #Shuffle the train data\n",
        "test_df = pd.read_csv('/content/drive/MyDrive/CSV/test{}.csv'.format(fold_num))#read test csv file (For evaluating the final version of the trained network)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvqnEK7hRf4M"
      },
      "source": [
        "#Create the generators\n",
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "      dataframe=train_df,\n",
        "      directory='data',\n",
        "      x_col=\"filename\",\n",
        "      y_col=\"class\",\n",
        "      target_size=shape[:2],\n",
        "      batch_size=10,\n",
        "      class_mode='categorical',color_mode=\"grayscale\",shuffle=True)\n",
        "validation_generator = test_datagen.flow_from_dataframe(\n",
        "        dataframe=validation_df,\n",
        "        directory='data',\n",
        "        x_col=\"filename\",\n",
        "        y_col=\"class\",\n",
        "        target_size=shape[:2],\n",
        "        batch_size=10,\n",
        "        class_mode='categorical',color_mode=\"grayscale\",shuffle=True)\n",
        "test_generator = test_datagen.flow_from_dataframe(\n",
        "        dataframe=test_df,\n",
        "        directory='data',\n",
        "        x_col=\"filename\",\n",
        "        y_col=\"class\",\n",
        "        target_size=shape[:2],\n",
        "        batch_size=10,\n",
        "        class_mode='categorical',color_mode=\"grayscale\",shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhGTOcC-QZ1o"
      },
      "source": [
        "k.clear_session() #Clear keras backend \n",
        "try:\n",
        "  os.mkdir('models') #create folder for saving the trained networks\n",
        "except:\n",
        "  pass\n",
        "full_name='ResNet152-FPN-fold{}'.format(fold_num)\n",
        "\n",
        "input_tensor=Input(shape=shape)\n",
        "weight_model = ResNet152(weights='imagenet', include_top=False) #Load ResNet152 ImageNet pre-trained weights\n",
        "weight_model.save_weights('weights.h5') #Save the weights\n",
        "base_model = ResNet152(weights=None, include_top=False, input_tensor=input_tensor) #Load the ResNet152 model without weights\n",
        "base_model.load_weights('weights.h5',skip_mismatch=True, by_name=True) #Load the ImageNet weights on the ResNet model except the first layer(because the first layer has one channel in our case)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_wALwcFyAcS"
      },
      "source": [
        "# Attaching our own FC\n",
        "\n",
        "x = base_model.output\n",
        "x = AveragePooling2D(pool_size = (2,2), padding = 'same', strides=(1,1))(x)\n",
        "x = Flatten(name = 'flatten_layer')(x)\n",
        "x = Dense(128, activation = 'relu')(x)\n",
        "x = Dropout(0.2)(x)\n",
        "output=Dense(num_class, activation='softmax',kernel_initializer=RandomNormal(mean=0.0, stddev=0.001))(x)\n",
        "model=Model(base_model.input, output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_S1v6gLX3Fv"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WP-WPUnNWuOO"
      },
      "source": [
        "plot_model(model, to_file='resnet152_model_plot.png', show_shapes=True, show_layer_names=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bGRV5bJbCDx"
      },
      "source": [
        "for layer in model.layers:\n",
        "  layer.trainable = True\n",
        "model.compile(optimizer=optimizers.Nadam(lr=0.0001), loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G52Vl1jVpO69"
      },
      "source": [
        "filepath=\"models/%s-{epoch:02d}-{val_accuracy:.4f}.hdf5\"%full_name  # Path to save the trained models\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', save_best_only=True, mode='max') #creating checkpoint to save the best validation accuracy\n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "log_dir=\"logs/fit\"+datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_moNtHHm0M5"
      },
      "source": [
        "history=model.fit(train_generator,steps_per_epoch=100, epochs=100, validation_data=validation_generator, shuffle=True,callbacks=[callbacks_list, tensorboard_callback]) #start training"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7K8VWpDxWQ3"
      },
      "source": [
        "# save entire model and weights\n",
        "model.save('Resnet152_model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVoGtVw7j1e0"
      },
      "source": [
        "# load model and weights\n",
        "#model=load_model('/content/drive/MyDrive/trained_models/resnet152_lstm_model.hdf5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7W7gyvR6M0O"
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir logs/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uznfKXU9-hwR"
      },
      "source": [
        "# summarize history for accuracy\n",
        "\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='lower right')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdOb4p-40F_3"
      },
      "source": [
        "score = model.evaluate(train_generator)\n",
        "print(\"Accuracy:%.2f%%\" % (score[1]*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3EcYxjQMu6T"
      },
      "source": [
        "score = model.evaluate(test_generator)\n",
        "print(\"Accuracy:%.2f%%\" % (score[1]*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dkCeLinPBhm"
      },
      "source": [
        "y_pred=model.predict(test_generator)\n",
        "ypred=np.argmax(y_pred, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vl183YMoFeYt"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cm=confusion_matrix(test_generator.classes, ypred)\n",
        "cm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KBqKSspLA0e"
      },
      "source": [
        "import seaborn as sns\r\n",
        "sns.heatmap(cm/np.sum(cm), annot=True, fmt='.2%', cmap='Blues')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXAxCmbEU2fR"
      },
      "source": [
        "class_labels=list(test_generator.class_indices.keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyjwHKexFwqF"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "# class_name=['Covid','Normal']\n",
        "print(classification_report(test_generator.classes, ypred, target_names=class_labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znfbM9Ma0r5-"
      },
      "source": [
        "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# make a prediction\n",
        "Y_pred = model.predict(test_generator, test_generator.samples // test_generator.batch_size+1) #(test_gen, steps=len(df_val), verbose=1)\n",
        "Ypred = np.argmax(y_pred, axis=1)\n",
        "fpr, tpr, thresholds = roc_curve(test_generator.classes, Ypred)\n",
        "auc_area = auc(fpr, tpr)\n",
        "\n",
        "\n",
        "plt.figure(1)\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.plot(fpr, tpr, label='area = {:.3f}'.format(auc_area))\n",
        "plt.xlabel('False positive rate')\n",
        "plt.ylabel('True positive rate')\n",
        "plt.title('ROC curve')\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhQsRrC7WV9w"
      },
      "source": [
        "!pip install scikit-plot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvgu9V_dQasr"
      },
      "source": [
        "true_classes=test_generator.classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLGum8EtU2VP"
      },
      "source": [
        "%matplotlib inline  \r\n",
        "import scikitplot as skplt\r\n",
        "\r\n",
        "[print(k, \":\", v) for k,v in enumerate(class_labels)]\r\n",
        "true_map_classes = [class_labels[x] for x in true_classes]\r\n",
        "predicted_map_classes = [class_labels[x] for x in ypred]\r\n",
        "\r\n",
        "skplt.metrics.plot_confusion_matrix(\r\n",
        "    true_map_classes, \r\n",
        "    predicted_map_classes,\r\n",
        "    labels=class_labels,\r\n",
        "    x_tick_rotation=90,\r\n",
        "    figsize=(6,6))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcBXi2VMU_xk"
      },
      "source": [
        "skplt.metrics.plot_precision_recall(true_classes, y_pred, figsize=(6,6))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tYCXzwHYavi"
      },
      "source": [
        "skplt.metrics.plot_roc(true_classes, y_pred, figsize=(6,6))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xE1h0BqQZ7C"
      },
      "source": [
        "#Model Evaluation\n",
        "trained_models=[]\n",
        "for r,d,f in os.walk('models'): #Take the path to the trained nets \n",
        "  for file in f:\n",
        "    if '.hdf5' in file:\n",
        "      trained_models.append(os.path.join(r,file))\n",
        "\n",
        "reports=[]\n",
        "for trn_model in trained_models: #evaluate the network on each trained net\n",
        "  k.clear_session()\n",
        "  netpath=trn_model \n",
        "  models_name=trn_model\n",
        "  fold_num=trn_model[trn_model.index('fold')+4] #find the fold number\n",
        "  net=keras.models.load_model(netpath) #load model\n",
        "\n",
        "  covid_label= test_generator.class_indices['covid'] #get the index of COVID-19 class \n",
        "  normal_label= test_generator.class_indices['normal']  #get the index of normal class \n",
        "  tp=0 #True Positives\n",
        "  fp=0 #False Positives\n",
        "  anum=0 #All the images numbers\n",
        "  ###########\n",
        "  ctp=0 #Correct classified COVID-19 cases\n",
        "  cfp=0 #Wrong classified COVID-19 cases\n",
        "  cfn=0 #Not classified COVID-19 cases\n",
        "  ctn=0 #Correctly not classified COVID-19 cases\n",
        "  cnum=0 #Number of COVID cases\n",
        "  ################\n",
        "  ntp=0 #Correct classified normal cases\n",
        "  nfp=0 #Wrong classified normal cases\n",
        "  nfn=0 #Not classified normal cases\n",
        "  ntn=0 #Correctly not classified normal cases\n",
        "  nnum=0 #Number of normal cases\n",
        "  for num,img_name in enumerate(test_generator.filenames): #load image\n",
        "    gt_ind=test_generator.classes[num] #get the loaded image class index\n",
        "    img=cv2.imread(os.path.join('data',img_name),cv2.IMREAD_UNCHANGED) #load image\n",
        "    pred_ind=np.argmax(net.predict(np.expand_dims(np.expand_dims(img,axis=0),axis=3))[0]) #get the predicted class index\n",
        "    anum+=1 #count the number of images\n",
        "    if gt_ind==covid_label:\n",
        "      cnum+=1\n",
        "      if pred_ind==covid_label:\n",
        "        tp+=1\n",
        "        ctp+=1\n",
        "        ntn+=1\n",
        "      else:\n",
        "        fp+=1\n",
        "        nfp+=1\n",
        "        cfn+=1\n",
        "    elif gt_ind==normal_label:\n",
        "      nnum+=1\n",
        "      if pred_ind==normal_label:\n",
        "        ctn+=1\n",
        "        ntp+=1\n",
        "        tp+=1\n",
        "      else:\n",
        "        cfp+=1\n",
        "        nfn+=1\n",
        "        fp+=1\n",
        "\n",
        "\n",
        "  overall_acc=tp/(tp+fp) #overall accuracy\n",
        "  cacc=(ctp+ctn)/(ctp+ctn+cfp+cfn) #covid accurayc\n",
        "  nacc=(ntp+ntn)/(ntp+ntn+nfp+nfn) #normal accuracy\n",
        "  csens=ctp/(ctp+cfn) #covid sensitivity\n",
        "  nsens=ntp/(ntp+nfn) #normal sensitivity\n",
        "  cspec=ctn/(ctn+cfp) #covid specificity\n",
        "  nspec=ntn/(ntn+nfp) #normal specificity\n",
        "  cprec=ctp/(ctp+cfp) #covid precision\n",
        "  nprec=ntp/(ntp+nfp) #normal precision\n",
        "\n",
        "  reports.append([models_name,fold_num,tp,fp,ctp,cfn,cfp,ntp,nfn,nfp,overall_acc,cacc,nacc,csens,nsens,cspec,nspec,cprec,nprec])\n",
        "\n",
        "\n",
        "  print(models_name)\n",
        "  print('tp: ',tp,'fp: ',fp)\n",
        "\n",
        "with open('FPN.csv', mode='w',newline='') as csv_file:\n",
        "    csvwriter = csv.writer(csv_file, delimiter=',', quotechar='\"',quoting=csv.QUOTE_MINIMAL)\n",
        "    csvwriter.writerow(['models_name','fold_num','tp','fp','ctp','cfn','cfp','ntp','nfn','nfp','overall_acc','cacc','nacc','csens','nsens','cspec','nspec','cprec','nprec'])\n",
        "    for row in reports:\n",
        "        csvwriter.writerow(row)  "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}