{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Reload_Model_Grad_Cam_COVID_ResNet152.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/youavang/Covid-19_CT_Scan_With_Deep_Learning/blob/main/Reload_Model_Grad_Cam_COVID_ResNet152.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yzu3iHOt4rf"
      },
      "source": [
        "# Down grade to tensorflow to 2.2.0 version in order to use tf-explain Grad CAM\n",
        "!pip install tensorflow==2.2.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6TMrpoyHzSy"
      },
      "source": [
        "# Import tf-explain in order to import Grad CAM for visualization.\n",
        "!pip install tf-explain==0.1.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bQacoopJRcu"
      },
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "import pandas as pd\n",
        "import csv\n",
        "import zipfile\n",
        "from keras import optimizers\n",
        "from keras.models import Sequential, Model, load_model\n",
        "from keras.layers import Dropout, Flatten, Dense, Input, AveragePooling2D, Reshape, Lambda\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization,TimeDistributed, LSTM, concatenate\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "from keras.preprocessing.image import ImageDataGenerator,save_img, load_img, img_to_array\n",
        "from keras.initializers import RandomNormal\n",
        "from sklearn.utils import shuffle\n",
        "import io\n",
        "from PIL import Image as pil_image\n",
        "import keras.backend as k\n",
        "from IPython.display import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "import tensorflow as tf\n",
        "import datetime\n",
        "from keras.callbacks import TensorBoard\n",
        "from keras.applications import ResNet152, InceptionV3, Xception, VGG16, VGG19\n",
        "from keras.applications.resnet_v2 import ResNet50V2\n",
        "from keras.utils.vis_utils import plot_model\n",
        "import tf_explain"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ry8HQosovrXY"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JmhSAzXPUaX"
      },
      "source": [
        "!nvidia-smi #show the allocated GPU"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1G82GuO-tez"
      },
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('To enable a high-RAM runtime, select the Runtime > \"Change runtime type\"')\n",
        "  print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')\n",
        "  print('re-execute this cell.')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1igZiqjnASJF"
      },
      "source": [
        "# Add the COVID-CTset to your drive through this link:\r\n",
        "#https://drive.google.com/drive/folders/1xdk-mCkxCDNwsMAk2SGv203rY1mrbnPB?usp=sharing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UAp6XlqPeou"
      },
      "source": [
        "#Install essential libraries\n",
        "!pip install zipfile36"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhzh5DCPgYhQ"
      },
      "source": [
        "archive = zipfile.ZipFile(\"/content/drive/MyDrive/Train&Validation.zip\") #Path to the shared data for training and validation\n",
        "for file in archive.namelist():\n",
        "     archive.extract(file, './data') #Extract the data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crj_9Nh3HpJS"
      },
      "source": [
        "random_seed = 123\n",
        "random.seed(random_seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzN_Dxg5V14k"
      },
      "source": [
        "fold_num=1 #Select Fold Number"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpjAiyH3bKIu"
      },
      "source": [
        "#Here we set the data generators for applying data augmentation methods\n",
        "train_datagen = ImageDataGenerator(horizontal_flip=True,vertical_flip=True,zoom_range=0.05,rotation_range=360,width_shift_range=0.05,height_shift_range=0.05,shear_range=0.05)\n",
        "test_datagen = ImageDataGenerator()\n",
        "train_df =pd.read_csv('/content/drive/MyDrive/CSV/train{}.csv'.format(fold_num)) #read train csv file\n",
        "validation_df = pd.read_csv('/content/drive/MyDrive/CSV/validation{}.csv'.format(fold_num)) #read validation csv file (Validation in the training process)\n",
        "train_df = shuffle(train_df) #Shuffle the train data\n",
        "test_df = pd.read_csv('/content/drive/MyDrive/CSV/test{}.csv'.format(fold_num))#read test csv file (For evaluating the final version of the trained network)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bITv5T0wVT-f"
      },
      "source": [
        "shape=(512,512,1) #shape of the dataset images (in TIFF format)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvqnEK7hRf4M"
      },
      "source": [
        "#Create the generators\n",
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "      dataframe=train_df,\n",
        "      directory='data',\n",
        "      x_col=\"filename\",\n",
        "      y_col=\"class\",\n",
        "      target_size=shape[:2],\n",
        "      batch_size=10,\n",
        "      class_mode='categorical',color_mode=\"grayscale\",shuffle=True)\n",
        "validation_generator = test_datagen.flow_from_dataframe(\n",
        "        dataframe=validation_df,\n",
        "        directory='data',\n",
        "        x_col=\"filename\",\n",
        "        y_col=\"class\",\n",
        "        target_size=shape[:2],\n",
        "        batch_size=10,\n",
        "        class_mode='categorical',color_mode=\"grayscale\",shuffle=True)\n",
        "test_generator = test_datagen.flow_from_dataframe(\n",
        "        dataframe=test_df,\n",
        "        directory='data',\n",
        "        x_col=\"filename\",\n",
        "        y_col=\"class\",\n",
        "        target_size=shape[:2],\n",
        "        batch_size=10,\n",
        "        class_mode='categorical',color_mode=\"grayscale\",shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TP5POu7gr5W9"
      },
      "source": [
        "# load entire model and weights\n",
        "model=keras.models.load_model('/content/drive/MyDrive/Models/resnet152_model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1oCPUKgF5r7"
      },
      "source": [
        "# import Grad CAM\n",
        "\n",
        "from tf_explain.core.grad_cam import GradCAM"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oP3eeRdLZGgw"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Qg7fEunTAeEP"
      },
      "source": [
        "y_pred=model.predict(test_generator)\n",
        "ypred=np.argmax(y_pred, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9z9YJx6XJw9s"
      },
      "source": [
        "# Create dataframe to save classification\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame() \n",
        "df['Images'] = test_generator.filenames\n",
        "df['classes'] = test_df['class']\n",
        "df['classes_int'] = test_generator.classes\n",
        "\n",
        "df['y_pred'] = np.argmax(y_pred, axis=1)\n",
        "\n",
        "conditions2 = [\n",
        "    (df['y_pred'] == 0),\n",
        "    (df['y_pred'] == 1),\n",
        "    ]\n",
        "pred_values = ['covid','normal']\n",
        "df['pred_class'] = np.select(conditions2, pred_values)\n",
        "\n",
        "# create a list of our conditions\n",
        "conditions = [\n",
        "    (df['classes_int'] == 0) & (df['y_pred'] == 0),\n",
        "    (df['classes_int'] == 0) & (df['y_pred'] == 1),\n",
        "    (df['classes_int'] == 1) & (df['y_pred'] == 1),\n",
        "    (df['classes_int'] == 1) & (df['y_pred'] == 0),\n",
        "    ]\n",
        "# create a list of the values we want to assign for each condition\n",
        "values = ['TP', 'FN', 'TN', 'FP']\n",
        "\n",
        "# create a new column and use np.select to assign values to it using our lists as arguments\n",
        "df['Prediction'] = np.select(conditions, values)\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', 20)\n",
        "pd.set_option('display.width', 100)\n",
        "print(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "sT_-o1wwd_wl"
      },
      "source": [
        "explainer = GradCAM()\n",
        "visual_layer='conv5_block3_out'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "eO2mYswnRWFu"
      },
      "source": [
        "!mkdir summary\n",
        "temp_folder ='./summary/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "gOux6zHZFcXu"
      },
      "source": [
        "name_paths = test_generator.filepaths\n",
        "name_paths[1:10]\n",
        "\n",
        "number_of_image_per_batch = 20\n",
        "list_of_random_items = random.sample(name_paths, number_of_image_per_batch)\n",
        "#print(list_of_random_items)\n",
        "\n",
        "# You must first create a folder in your Google Drive in order to save your images, \n",
        "# then past the path here.\n",
        "save_folder =\"/content/drive/MyDrive/Gradcam Images/resnet152/\"\n",
        "columns = 2\n",
        "rows = len(list_of_random_items)\n",
        "\n",
        "input_arrays = []\n",
        "data_array = []\n",
        "i = 1\n",
        "j = 1\n",
        "\n",
        "for batch in range(50):\n",
        "  random.seed(random_seed)\n",
        "  random_seed += 100\n",
        "  list_of_random_items = random.sample(name_paths, number_of_image_per_batch)\n",
        "  fig=plt.figure(figsize=(15, 20*rows/2.5))\n",
        "  i = 1\n",
        "  j = 1\n",
        "  for paths in list_of_random_items:\n",
        "    img = load_img(paths)\n",
        "\n",
        "    pic = load_img(paths, color_mode='grayscale', target_size=(512,512,1))\n",
        "    pic_arr = img_to_array(pic)\n",
        "   \n",
        "    d = ([pic_arr], None)\n",
        "    data = ([pic_arr], None)\n",
        "    grid = explainer.explain(data, model, layer_name=visual_layer, class_index=0) \n",
        "    file_save = paths.split('/')[1].replace('.tif','')+ \"grad_cam\" + \".png\"\n",
        "  \n",
        "    #print(file_save)\n",
        "    explainer.save(grid, save_folder + 'batch_'+str(batch), file_save)\n",
        "\n",
        "    pic_gradCam_path = save_folder + 'batch_'+str(batch)+ '/' + file_save\n",
        "    pic_gradCam = load_img(pic_gradCam_path)\n",
        "    j = i+1\n",
        "    #save image to view\n",
        "\n",
        "    f = open(paths, 'rb')\n",
        "    tif = pil_image.open(io.BytesIO(f.read()))\n",
        "    array = np.array(tif)\n",
        "    max_val = np.amax(array)\n",
        "    normalized = (array/max_val)\n",
        "    im_view = pil_image.fromarray(normalized)\n",
        "    im_view_path = paths.split('/')[1].replace('.tif','')\n",
        "    #save_path = save_folder+ 'batch_'+str(batch)+'/' + im_view_path + '_view.tif'\n",
        "    #im_view.save(save_path)\n",
        "\n",
        "    #print(save_path)\n",
        "    image_name = paths.split('/')[1]\n",
        "    act_class = df.loc[df['Images'] == image_name].classes.tolist()[0]\n",
        "    pred_class = df.loc[df['Images'] == image_name].pred_class.tolist()[0]\n",
        "    pred = df.loc[df['Images'] == image_name].Prediction.tolist()[0]\n",
        "\n",
        "    plt.axis('off')\n",
        "    fig.add_subplot(rows, columns, i)\n",
        "    plt.title(image_name+'\\n Actual class: '+act_class+'\\n Pred Class: '+\n",
        "              pred_class+'\\n Accuracy: '+ pred)\n",
        "    plt.imshow(pic)\n",
        "    plt.axis('off')\n",
        "    fig.add_subplot(rows, columns, i+1)\n",
        "    fig.tight_layout()\n",
        "    plt.title(file_save+'\\n Actual class: '+act_class+'\\n Pred Class: '+\n",
        "              pred_class+'\\n Accuracy: '+ pred)\n",
        "    plt.imshow(pic_gradCam)\n",
        "\n",
        "    i = i + 2\n",
        "  plt.axis('off')\n",
        "  plt.show()\n",
        "  fig.savefig(save_folder+'Summary\\Batch'+str(batch)+'plot.pdf', dpi = 200)\n",
        "  plt.savefig(save_folder+'Summary\\Batch'+str(batch)+'plot.png', dpi = 200)\n",
        "  fig.savefig(temp_folder + 'Batch'+str(batch)+'plot.pdf', dpi = 300)\n",
        "  plt.savefig(temp_folder +'Batch'+str(batch)+'plot.png', dpi = 300)\n",
        "\n",
        "fig.savefig('plot.pdf', dpi = 300)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cT1_uHDsWnch"
      },
      "source": [
        "from google.colab import files\n",
        "import shutil\n",
        "sum_path = 'summary_resnet152'\n",
        "shutil.make_archive(sum_path, 'zip', temp_folder)\n",
        "\n",
        "#!zip -r 'sum_path' /content/summary\n",
        "files.download(sum_path+'.zip')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOKlYyiPyiuu"
      },
      "source": [
        "## This next section is using a pre-trained model that is not trained on any dataset. You just have it look at a picture and let it tell you what is important.\r\n",
        "\r\n",
        "You can find the codes from this resource:\r\n",
        "https://keras.io/examples/vision/grad_cam/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFgvbaX41-aV"
      },
      "source": [
        "#img_path = '/content/drive/MyDrive/Train&Validation/137covid_patient10_SR_4_IM00068.tif'\n",
        "img_path ='/content/drive/MyDrive/Train&Validation/137covid_patient118_SR_3_IM00014.tif'# good\n",
        "img = load_img(img_path)\n",
        "plt.imshow(img)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlNHFVf-AC0v"
      },
      "source": [
        "model_builder = keras.applications.xception.Xception\n",
        "img_size = (299,299)\n",
        "preprocess_input = keras.applications.xception.preprocess_input\n",
        "decode_predictions = keras.applications.xception.decode_predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6ojc2_9lWiI"
      },
      "source": [
        "model_builder.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXrYi7RqVTjt"
      },
      "source": [
        "last_conv_layer_name = \"block14_sepconv2_act\"\n",
        "classifier_layer_names = [\"avg_pool\", \"predictions\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7aTIdAyqBpW"
      },
      "source": [
        "pix=load_img(img_path, color_mode='grayscale', target_size=(512,512))\n",
        "plt.imshow(pix)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hKRORQT2n_O"
      },
      "source": [
        "def get_img_array(img_path, size):\n",
        "    # `img` is a PIL image of size 299x299\n",
        "    img = load_img(img_path, target_size=size)\n",
        "    # `array` is a float32 Numpy array of shape (299, 299, 3)\n",
        "    array = img_to_array(img)\n",
        "    # We add a dimension to transform our array into a \"batch\"\n",
        "    # of size (1, 299, 299, 3)\n",
        "    array = np.expand_dims(array, axis=0)\n",
        "    return array\n",
        "\n",
        "\n",
        "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, classifier_layer_names):\n",
        "    # First, we create a model that maps the input image to the activations\n",
        "    # of the last conv layer\n",
        "    last_conv_layer = model.get_layer(last_conv_layer_name)\n",
        "    last_conv_layer_model = Model(model.inputs, last_conv_layer.output)\n",
        "\n",
        "    # Second, we create a model that maps the activations of the last conv\n",
        "    # layer to the final class predictions\n",
        "    classifier_input = keras.Input(shape=last_conv_layer.output.shape[1:])\n",
        "    x = classifier_input\n",
        "    for layer_name in classifier_layer_names:\n",
        "        x = model.get_layer(layer_name)(x)\n",
        "    classifier_model = Model(classifier_input, x)\n",
        "\n",
        "    # Then, we compute the gradient of the top predicted class for our input image\n",
        "    # with respect to the activations of the last conv layer\n",
        "    with tf.GradientTape() as tape:\n",
        "        # Compute activations of the last conv layer and make the tape watch it\n",
        "        last_conv_layer_output = last_conv_layer_model(img_array)\n",
        "        tape.watch(last_conv_layer_output)\n",
        "        # Compute class predictions\n",
        "        preds = classifier_model(last_conv_layer_output)\n",
        "        top_pred_index = tf.argmax(preds[0])\n",
        "        top_class_channel = preds[:, top_pred_index]\n",
        "\n",
        "    # This is the gradient of the top predicted class with regard to\n",
        "    # the output feature map of the last conv layer\n",
        "    grads = tape.gradient(top_class_channel, last_conv_layer_output)\n",
        "\n",
        "    # This is a vector where each entry is the mean intensity of the gradient\n",
        "    # over a specific feature map channel\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "\n",
        "    # We multiply each channel in the feature map array\n",
        "    # by \"how important this channel is\" with regard to the top predicted class\n",
        "    last_conv_layer_output = last_conv_layer_output.numpy()[0]\n",
        "    pooled_grads = pooled_grads.numpy()\n",
        "    for i in range(pooled_grads.shape[-1]):\n",
        "        last_conv_layer_output[:, :, i] *= pooled_grads[i]\n",
        "\n",
        "    # The channel-wise mean of the resulting feature map\n",
        "    # is our heatmap of class activation\n",
        "    heatmap = np.mean(last_conv_layer_output, axis=-1)\n",
        "\n",
        "    # For visualization purpose, we will also normalize the heatmap between 0 & 1\n",
        "    heatmap = np.maximum(heatmap, 0) / np.max(heatmap)\n",
        "    return heatmap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQ23y_ax-4ub"
      },
      "source": [
        "# Prepare image\n",
        "img_array = preprocess_input(get_img_array(img_path, size=img_size))\n",
        "\n",
        "# Make model\n",
        "model = model_builder(weights=\"imagenet\")\n",
        "\n",
        "# Print what the top predicted class is\n",
        "preds = model.predict(img_array)\n",
        "print(\"Predicted:\", decode_predictions(preds, top=1)[0])\n",
        "\n",
        "# Generate class activation heatmap\n",
        "heatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name, classifier_layer_names)\n",
        "\n",
        "# Display heatmap\n",
        "plt.matshow(heatmap)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uvqk7u9t_G4Z"
      },
      "source": [
        "# We load the original image\n",
        "img = keras.preprocessing.image.load_img(img_path)\n",
        "img = keras.preprocessing.image.img_to_array(img)\n",
        "\n",
        "# We rescale heatmap to a range 0-255\n",
        "heatmap = np.uint8(255 * heatmap)\n",
        "\n",
        "# We use jet colormap to colorize heatmap\n",
        "jet = cm.get_cmap(\"jet\")\n",
        "\n",
        "# We use RGB values of the colormap\n",
        "jet_colors = jet(np.arange(256))[:, :3]\n",
        "jet_heatmap = jet_colors[heatmap]\n",
        "\n",
        "# We create an image with RGB colorized heatmap\n",
        "jet_heatmap = keras.preprocessing.image.array_to_img(jet_heatmap)\n",
        "jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n",
        "jet_heatmap = keras.preprocessing.image.img_to_array(jet_heatmap)\n",
        "\n",
        "# Superimpose the heatmap on original image\n",
        "superimposed_img = jet_heatmap * 0.4 + img\n",
        "superimposed_img = keras.preprocessing.image.array_to_img(superimposed_img)\n",
        "\n",
        "# Save the superimposed image\n",
        "save_path = \"covidp1.jpg\"\n",
        "superimposed_img.save(save_path)\n",
        "\n",
        "# Display Grad CAM\n",
        "display(Image(save_path))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}